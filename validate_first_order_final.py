#!/usr/bin/env python
"""
Final comprehensive validation for FirstOrderMarkovChain.
Tests all functionality from the user's requirements.
"""

import sys
from pathlib import Path


def test_imports():
    """Test that imports work correctly."""
    print("=" * 70)
    print("1. Testing Imports")
    print("=" * 70)

    try:
        from src.markov import FirstOrderMarkovChain
        print("‚úÖ Import successful: FirstOrderMarkovChain")
        return True, FirstOrderMarkovChain
    except ImportError as e:
        print(f"‚ùå Import failed: {e}")
        return False, None


def test_training(FirstOrderMarkovChain):
    """Test all training methods."""
    print("\n" + "=" * 70)
    print("2. Testing Training Methods")
    print("=" * 70)

    try:
        sequences = [
            ['login', 'profile', 'browse', 'product', 'cart'],
            ['login', 'profile', 'orders'],
            ['login', 'browse', 'product', 'product', 'cart', 'checkout'],
            ['browse', 'search', 'product', 'cart'],
        ]

        mc = FirstOrderMarkovChain(smoothing=0.001)

        # Test fit
        mc.fit(sequences)
        assert mc.is_fitted, "Model should be fitted"
        print("‚úÖ fit() works correctly")

        # Test partial_fit
        initial_count = len(mc.states)
        mc.partial_fit([['new_state', 'another_state']])
        assert len(mc.states) > initial_count, "Should add new states"
        print("‚úÖ partial_fit() works correctly")

        # Test update
        mc.update('test_from', 'test_to', count=5)
        assert 'test_from' in mc.states
        print("‚úÖ update() works correctly")

        return True, mc

    except Exception as e:
        print(f"‚ùå Training failed: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_prediction(mc):
    """Test prediction methods."""
    print("\n" + "=" * 70)
    print("3. Testing Prediction Methods")
    print("=" * 70)

    try:
        # Test predict
        predictions = mc.predict('login', k=3)
        assert isinstance(predictions, list), "Should return list"
        assert len(predictions) > 0, "Should have predictions"
        assert all(len(p) == 2 for p in predictions), "Each prediction should be (state, prob)"
        print(f"‚úÖ predict() works: {len(predictions)} predictions for 'login'")

        # Test predict_proba
        prob = mc.predict_proba('login', 'profile')
        assert isinstance(prob, float), "Should return float"
        assert 0 <= prob <= 1, "Probability should be in [0, 1]"
        print(f"‚úÖ predict_proba() works: P(profile|login) = {prob:.3f}")

        return True

    except Exception as e:
        print(f"‚ùå Prediction failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_sequence_operations(mc):
    """Test sequence generation and scoring."""
    print("\n" + "=" * 70)
    print("4. Testing Sequence Operations")
    print("=" * 70)

    try:
        # Test generate_sequence
        seq = mc.generate_sequence('login', length=10, seed=42)
        assert isinstance(seq, list), "Should return list"
        assert len(seq) <= 10, "Should respect length limit"
        assert seq[0] == 'login', "Should start with given state"
        print(f"‚úÖ generate_sequence() works: generated {len(seq)} states")

        # Test score_sequence
        score = mc.score_sequence(['login', 'profile', 'orders'])
        assert isinstance(score, float), "Should return float"
        print(f"‚úÖ score_sequence() works: score = {score:.3f}")

        return True

    except Exception as e:
        print(f"‚ùå Sequence operations failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_evaluation(mc):
    """Test evaluation metrics."""
    print("\n" + "=" * 70)
    print("5. Testing Evaluation")
    print("=" * 70)

    try:
        test_sequences = [
            ['login', 'profile', 'browse'],
            ['browse', 'product', 'cart']
        ]

        metrics = mc.evaluate(test_sequences, k_values=[1, 3, 5])

        required_metrics = ['top_1_accuracy', 'top_3_accuracy', 'top_5_accuracy',
                          'mrr', 'coverage', 'perplexity']

        for metric in required_metrics:
            assert metric in metrics, f"Missing metric: {metric}"

        print(f"‚úÖ evaluate() works:")
        print(f"   Top-1 accuracy: {metrics['top_1_accuracy']:.2%}")
        print(f"   MRR: {metrics['mrr']:.3f}")
        print(f"   Coverage: {metrics['coverage']:.2%}")

        return True

    except Exception as e:
        print(f"‚ùå Evaluation failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_persistence(mc):
    """Test save/load functionality."""
    print("\n" + "=" * 70)
    print("6. Testing Persistence")
    print("=" * 70)

    try:
        from src.markov import FirstOrderMarkovChain
        import os

        # Save
        test_file = '_test_mc_temp.json'
        mc.save(test_file)
        assert Path(test_file).exists(), "File should be created"
        print(f"‚úÖ save() works: saved to {test_file}")

        # Load
        mc_loaded = FirstOrderMarkovChain.load(test_file)
        assert mc_loaded.is_fitted, "Loaded model should be fitted"
        assert mc_loaded.states == mc.states, "States should match"
        print(f"‚úÖ load() works: loaded {len(mc_loaded.states)} states")

        # Clean up
        os.remove(test_file)

        return True

    except Exception as e:
        print(f"‚ùå Persistence failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_properties(mc):
    """Test properties and statistics."""
    print("\n" + "=" * 70)
    print("7. Testing Properties")
    print("=" * 70)

    try:
        # Test is_fitted
        assert mc.is_fitted == True, "Should be fitted"
        print(f"‚úÖ is_fitted property works: {mc.is_fitted}")

        # Test states
        states = mc.states
        assert isinstance(states, set), "Should return set"
        assert len(states) > 0, "Should have states"
        print(f"‚úÖ states property works: {len(states)} states")

        # Test get_statistics
        stats = mc.get_statistics()
        assert 'is_fitted' in stats
        assert 'num_states' in stats
        assert 'num_transitions' in stats
        print(f"‚úÖ get_statistics() works:")
        print(f"   States: {stats['num_states']}")
        print(f"   Transitions: {stats['num_transitions']}")

        return True

    except Exception as e:
        print(f"‚ùå Properties failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_user_requirements():
    """Test the exact example from user's requirements."""
    print("\n" + "=" * 70)
    print("8. Testing User Requirements Example")
    print("=" * 70)

    try:
        from src.markov.first_order import FirstOrderMarkovChain

        sequences = [
            ['login', 'profile', 'browse', 'product', 'cart'],
            ['login', 'profile', 'orders'],
            ['login', 'browse', 'product', 'product', 'cart', 'checkout'],
            ['browse', 'search', 'product', 'cart'],
        ]

        mc = FirstOrderMarkovChain(smoothing=0.001)
        mc.fit(sequences)

        print(f"Known states: {mc.states}")
        print(f"Number of states: {len(mc.states)}")

        print(f"\nPredictions after 'login': {mc.predict('login', k=3)}")
        print(f"Predictions after 'product': {mc.predict('product', k=3)}")

        metrics = mc.evaluate(sequences, k_values=[1, 3])
        print(f"\nTop-1 accuracy: {metrics['top_1_accuracy']:.3f}")
        print(f"MRR: {metrics['mrr']:.3f}")

        print("\n‚úÖ User requirements example works perfectly")
        return True

    except Exception as e:
        print(f"‚ùå User requirements test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_files():
    """Check that all required files exist."""
    print("\n" + "=" * 70)
    print("9. Checking Files")
    print("=" * 70)

    files = [
        "src/markov/first_order.py",
        "src/markov/__init__.py",
        "tests/unit/test_first_order.py",
        "FIRST_ORDER_QUICK_REF.md",
        "demo_first_order.py",
        "validate_first_order.py",
    ]

    all_exist = True
    for file_path in files:
        path = Path(file_path)
        if path.exists():
            size = path.stat().st_size
            print(f"‚úÖ {file_path:40s} ({size:6,} bytes)")
        else:
            print(f"‚ùå {file_path:40s} (missing)")
            all_exist = False

    return all_exist


def main():
    """Run all validation tests."""
    print("\n" + "‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 10 + "FirstOrderMarkovChain - Final Validation" + " " * 17 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    results = []

    # Test imports
    success, FirstOrderMarkovChain = test_imports()
    results.append(("Imports", success))
    if not success:
        return 1

    # Test training
    success, mc = test_training(FirstOrderMarkovChain)
    results.append(("Training", success))
    if not success:
        return 1

    # Test prediction
    success = test_prediction(mc)
    results.append(("Prediction", success))

    # Test sequence operations
    success = test_sequence_operations(mc)
    results.append(("Sequence Operations", success))

    # Test evaluation
    success = test_evaluation(mc)
    results.append(("Evaluation", success))

    # Test persistence
    success = test_persistence(mc)
    results.append(("Persistence", success))

    # Test properties
    success = test_properties(mc)
    results.append(("Properties", success))

    # Test user requirements
    success = test_user_requirements()
    results.append(("User Requirements", success))

    # Check files
    success = check_files()
    results.append(("Files", success))

    # Summary
    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70 + "\n")

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status}  {name}")

    print(f"\n  Total: {passed}/{total} tests passed")

    if passed == total:
        print("\n" + "üéâ" * 35)
        print("\n  ‚ú® ALL VALIDATION TESTS PASSED! ‚ú®")
        print("\n  The FirstOrderMarkovChain implementation is:")
        print("    ‚úÖ Fully functional")
        print("    ‚úÖ Meets all requirements")
        print("    ‚úÖ Production ready")
        print("    ‚úÖ Well documented")
        print("\n  Features implemented:")
        print("    ‚Ä¢ fit(), partial_fit(), update() for training")
        print("    ‚Ä¢ predict(), predict_proba() for predictions")
        print("    ‚Ä¢ generate_sequence() for synthetic data")
        print("    ‚Ä¢ score_sequence() for anomaly detection")
        print("    ‚Ä¢ evaluate() with 6 metrics")
        print("    ‚Ä¢ save(), load() for persistence")
        print("    ‚Ä¢ is_fitted, states properties")
        print("\n  Next steps:")
        print("    ‚Ä¢ Run: python demo_first_order.py")
        print("    ‚Ä¢ Read: FIRST_ORDER_QUICK_REF.md")
        print("    ‚Ä¢ Integrate with your caching system!")
        print("\n" + "üéâ" * 35 + "\n")
        return 0
    else:
        print("\n‚ùå Some tests failed. Please review the errors above.\n")
        return 1


if __name__ == "__main__":
    sys.exit(main())

