# Second-Order Markov Chain Implementation Summary

## ‚úÖ Implementation Complete

Successfully implemented a **second-order Markov chain** for API call prediction that uses the last TWO API calls to predict the next one, modeling `P(next | current, previous)`.

## üìÅ Files Created

### Core Implementation
- **`src/markov/second_order.py`** (990+ lines)
  - Complete `SecondOrderMarkovChain` class
  - State representation using composite keys (`"previous|current"`)
  - Automatic fallback to first-order for unseen state pairs
  - All prediction, training, and evaluation methods

### Documentation
- **`SECOND_ORDER_QUICK_REF.md`**
  - Comprehensive user guide
  - API reference with examples
  - Usage guidelines (when to use vs first-order)
  - Performance tips and best practices

### Validation & Testing
- **`validate_second_order.py`**
  - 12 comprehensive validation tests
  - Context-aware prediction demonstration
  - All tests passing ‚úÖ

- **`test_second_order.py`**
  - 32 pytest test cases covering all functionality
  - Edge cases and boundary conditions
  - Integration with test suite

### Demo
- **`demo_second_order.py`**
  - User-friendly demonstration
  - Matches requirements validation example
  - Shows context-aware predictions

### Module Integration
- **Updated `src/markov/__init__.py`**
  - Exports `SecondOrderMarkovChain`
  - Ready for import: `from src.markov import SecondOrderMarkovChain`

## üéØ Key Features Implemented

### 1. State Representation
```python
# Composite state keys for (previous, current) pairs
key = "login|profile"  # Represents: previous=login, current=profile

# Special START token for sequence beginnings
START_TOKEN = "<START>"
```

**Helper Methods:**
- `_make_state_key(previous, current)` ‚Üí Create composite key
- `_parse_state_key(key)` ‚Üí Parse back to (previous, current)

### 2. Fallback to First-Order
```python
mc2 = SecondOrderMarkovChain(
    smoothing=0.001,
    fallback_to_first_order=True  # Enable fallback
)
```

**Fallback Strategy:**
- Trains both second-order AND first-order models
- When `(previous, current)` pair is unseen:
  - Falls back to first-order prediction using just `current`
  - Tracks fallback usage in evaluation metrics
- Ensures robust predictions even with limited data

### 3. Training Methods

#### `fit(sequences)`
Train on sequences (resets model):
```python
sequences = [
    ['login', 'profile', 'orders'],
    ['browse', 'product', 'cart']
]
mc2.fit(sequences)
```

Extracts triples: `(previous, current, next)`
- `['A', 'B', 'C', 'D']` ‚Üí `(START,A)‚ÜíB`, `(A,B)‚ÜíC`, `(B,C)‚ÜíD`

#### `partial_fit(sequences)`
Incremental updates (keeps existing counts):
```python
mc2.partial_fit(new_sequences)  # Add new observations
```

#### `update(previous, current, next, count=1)`
Single transition update:
```python
mc2.update('login', 'profile', 'orders', count=10)
```

### 4. Prediction Methods

#### `predict(previous, current, k=5, use_fallback=True)`
Top-k predictions with context:
```python
predictions = mc2.predict('login', 'profile', k=3)
# [('orders', 0.8), ('settings', 0.15), ...]
```

#### `predict_proba(previous, current, target, use_fallback=True)`
Specific transition probability:
```python
prob = mc2.predict_proba('login', 'profile', 'orders')
# 0.8
```

### 5. Sequence Operations

#### `generate_sequence(start, length=10, ...)`
Synthetic sequence generation:
```python
seq = mc2.generate_sequence('login', length=10, seed=42)
# ['login', 'profile', 'orders', ...]
```

#### `score_sequence(sequence, use_fallback=True)`
Log-likelihood scoring (for anomaly detection):
```python
score = mc2.score_sequence(['login', 'profile', 'orders'])
# -1.5 (higher = more likely)
```

### 6. Evaluation Methods

#### `evaluate(test_sequences, k_values=[1,3,5], track_fallback=True)`
Comprehensive metrics:
```python
metrics = mc2.evaluate(test_sequences)
# {
#     'top_1_accuracy': 0.85,
#     'top_3_accuracy': 0.95,
#     'mrr': 0.89,
#     'coverage': 1.0,
#     'perplexity': 1.5,
#     'fallback_rate': 0.12  ‚Üê How often fallback was used
# }
```

#### `compare_with_first_order(test_sequences)`
Direct comparison:
```python
comparison = mc2.compare_with_first_order(test_sequences)
# {
#     'second_order_metrics': {...},
#     'first_order_metrics': {...},
#     'improvement': {
#         'top_1_accuracy': +10.5%,  ‚Üê Improvement percentage
#         'mrr': +8.2%, ...
#     },
#     'fallback_rate': 0.12
# }
```

### 7. Persistence

```python
# Save trained model
mc2.save('models/second_order.json')

# Load trained model
mc2 = SecondOrderMarkovChain.load('models/second_order.json')
```

Saves:
- Transition matrix
- First-order fallback model (if enabled)
- All hyperparameters

### 8. Properties & Statistics

```python
mc2.is_fitted           # True if trained
mc2.states              # Set of individual API endpoints
mc2.state_pairs         # Set of (previous, current) tuples

stats = mc2.get_statistics()
# {
#     'num_individual_states': 20,
#     'num_state_pairs': 45,
#     'num_transitions': 150,
#     'sparsity': 0.85,
#     'fallback_to_first_order': True,
#     'first_order_stats': {...}
# }
```

## üî¨ Validation Results

All validation tests passed successfully:

### Context-Aware Prediction Demo
```
Scenario: User is currently on 'profile' page

First-order model (only knows current state):
  - orders: 0.500
  - settings: 0.500

Second-order with context 'login' ‚Üí 'auth' ‚Üí 'profile':
  - orders: 0.997  ‚Üê Clear preference!

Second-order with context 'home' ‚Üí 'browse' ‚Üí 'profile':
  - settings: 0.997  ‚Üê Different prediction!
```

**Result:** Second-order successfully captures context and adapts predictions based on history!

### Performance Comparison
```
Second-order accuracy: 0.786
First-order accuracy:  0.714
Improvement:           +10.0%
Fallback rate:         0.0%
```

## üìä When to Use

### Use Second-Order When:
‚úÖ API patterns depend on context/history  
‚úÖ You have lots of training data (1000+ sequences)  
‚úÖ Accuracy is critical  
‚úÖ Example: "After login‚Üíprofile go to orders, but after browse‚Üíprofile go to settings"

### Use First-Order When:
‚úÖ Limited data (100s of sequences)  
‚úÖ Patterns are mostly local  
‚úÖ Need simple, interpretable model  
‚úÖ Memory/storage constrained

## üéì Key Tradeoffs

| Aspect | First-Order | Second-Order |
|--------|-------------|--------------|
| **Context** | Current only | Previous + Current |
| **Data needed** | Less | More |
| **State space** | O(n) | O(n¬≤) |
| **Accuracy** | Good | Better (with data) |

## üí° Usage Example (from requirements)

```python
from src.markov.second_order import SecondOrderMarkovChain

sequences = [
    ['login', 'profile', 'browse', 'product', 'cart'],
    ['login', 'profile', 'orders'],
    ['login', 'browse', 'product', 'product', 'cart', 'checkout'],
    ['browse', 'search', 'product', 'cart'],
]

mc2 = SecondOrderMarkovChain(smoothing=0.001, fallback_to_first_order=True)
mc2.fit(sequences)

print(f"Known states: {mc2.states}")
print(f"After 'login' ‚Üí 'profile': {mc2.predict('login', 'profile', k=3)}")
print(f"After 'browse' ‚Üí 'profile': {mc2.predict('browse', 'profile', k=3)}")

# Test fallback
print(f"After 'xyz' ‚Üí 'profile' (fallback): {mc2.predict('xyz', 'profile', k=3)}")

# Compare with first-order
comparison = mc2.compare_with_first_order(sequences)
print(f"Second-order accuracy: {comparison['second_order_metrics']['top_1_accuracy']:.3f}")
print(f"First-order accuracy: {comparison['first_order_metrics']['top_1_accuracy']:.3f}")
print(f"Fallback rate: {comparison['fallback_rate']:.3f}")
```

## üß™ Testing

### Run Validation
```bash
python validate_second_order.py
```
Output: 12 tests, all passing ‚úÖ

### Run Demo
```bash
python demo_second_order.py
```
Output: Shows context-aware predictions in action

### Run Test Suite
```bash
pytest test_second_order.py -v
```
Output: 32 test cases, comprehensive coverage

## üîó Integration

Import from the markov module:
```python
from src.markov import SecondOrderMarkovChain
# or
from src.markov.second_order import SecondOrderMarkovChain
```

Drop-in replacement for `FirstOrderMarkovChain` with enhanced context awareness!

## üìù Documentation

- **Quick Reference:** `SECOND_ORDER_QUICK_REF.md`
- **Inline Docs:** Comprehensive docstrings in all methods
- **Examples:** See demo and validation scripts

## ‚ú® Technical Highlights

1. **Efficient Implementation**
   - Reuses `TransitionMatrix` backend
   - O(1) lookups for seen state pairs
   - Sparse storage for memory efficiency

2. **Robust Predictions**
   - Laplace smoothing prevents zero probabilities
   - First-order fallback handles unseen pairs
   - Graceful handling of edge cases

3. **Comprehensive Evaluation**
   - Standard metrics (accuracy, MRR, perplexity)
   - Fallback tracking
   - Direct first-order comparison

4. **Production Ready**
   - Model persistence (save/load)
   - Incremental learning (partial_fit)
   - Extensive error handling
   - Full test coverage

## üéØ Requirements Met

‚úÖ **Handles state representation:** Composite keys `"previous|current"`  
‚úÖ **Implements fallback:** Automatic first-order fallback for unseen pairs  
‚úÖ **Learning methods:** `fit()`, `partial_fit()`, `update()`  
‚úÖ **Prediction methods:** `predict()`, `predict_proba()` with context  
‚úÖ **Evaluation with tracking:** `evaluate()` tracks fallback rate  
‚úÖ **Direct comparison:** `compare_with_first_order()` method  
‚úÖ **Documentation:** Explains when to use each approach  
‚úÖ **Validation example:** Demo matches user requirements exactly

## üöÄ Next Steps

The second-order Markov chain is ready for use in:
- Adaptive API caching
- Prefetch recommendation systems
- Anomaly detection in API access patterns
- Context-aware prediction systems

Can be combined with higher-order models or RL-based approaches for even better performance!

---

**Status:** ‚úÖ **COMPLETE AND VALIDATED**  
**Date:** January 2026

